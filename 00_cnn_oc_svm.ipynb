{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp cnn_oc_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cnn_oc_svm\n",
    "\n",
    "> Contains the base class for the CNN OC-SVM model. Override the SVM or CNN as desired but used directly is optimized for the MNIST example case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "\n",
    "class cnn_oc_svm:\n",
    "    \"\"\"\n",
    "    The base-class for building a neural network with oc-SVM.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, neural_net, criterion, optimizer):\n",
    "        self.neural_net = neural_net\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.original_transforms = None\n",
    "        self.oc_svm = None\n",
    "\n",
    "    def training(self, epochs, learning_rate, training_data_loader, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Basic training function for nn.Sequence style models.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            running_loss = 0\n",
    "            for images, labels in training_data_loader:\n",
    "                images = images.view(images.shape[0], -1)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                predicted_labels = self.neural_net(images)\n",
    "                loss = self.criterion(predicted_labels, labels)\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Epoch {epoch} - Training loss: {running_loss/len(training_data_loader)}\"\n",
    "                )\n",
    "\n",
    "        print(f\"Training time (s): {time.time()-start_time}\")\n",
    "        return running_loss / len(training_data_loader)\n",
    "\n",
    "    def evaluation(self, validation_data_loader):\n",
    "        \"\"\"\n",
    "        Simple evaluation function to check neural network accuracy\n",
    "        \"\"\"\n",
    "        correct_classification, total_count = 0, 0\n",
    "        for images, labels in validation_data_loader:\n",
    "            for i in range(len(labels)):\n",
    "                img = images[i].view(1, 784)\n",
    "\n",
    "                with torch.no_grad():  # no grad because we are evaluation mode! using .eval() might work too\n",
    "                    log_probabilities = model(img)\n",
    "                probabilities = list(torch.exp(log_probabilities).numpy()[0])\n",
    "\n",
    "                predicted_label = probabilities.index(max(probabilities))\n",
    "                true_label = labels.numpy()[i]\n",
    "\n",
    "                if predicted_label == true_label:\n",
    "                    correct_classification += 1\n",
    "\n",
    "                total_count += 1\n",
    "        print(\n",
    "            f\"Images tested: {total_count} \\n Classification Accuracy: {correct_classification/total_count}\"\n",
    "        )\n",
    "        return correct_classification / total_count\n",
    "\n",
    "    def train_oc_svm(self, training_data_loader, amount_to_train_on=None):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        image_to_feature_transform = self.neural_net[:-2].eval()\n",
    "        # load up our to numpy and image to feature vector transforms\n",
    "        oc_svm_data_transforms = transforms.Compose(\n",
    "            [\n",
    "                lambda x: x.view(-1, 28 ** 2),\n",
    "                lambda x: image_to_feature_transform(x),\n",
    "                lambda x: x.detach().numpy(),\n",
    "                lambda x: x.flatten(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        training_data = list()\n",
    "        if amount_to_train_on == None:\n",
    "            amount_to_train_on = len(training_data_loader.dataset)\n",
    "        while len(training_data) < amount_to_train_on:\n",
    "            image, _ = next(iter(training_data_loader))\n",
    "            training_data.extend([oc_svm_data_transforms(im) for im in image])\n",
    "        training_data = np.array(training_data)\n",
    "\n",
    "        self.oc_svm = OneClassSVM()\n",
    "        print(f\"Fitting One Class SVM on {len(training_data)} data points\")\n",
    "        self.oc_svm.fit(training_data)\n",
    "\n",
    "        if self.oc_svm.fit_status_ != 0:\n",
    "            print(f\"OC SVM incorrectly fitted, try refitting?\")\n",
    "        else:\n",
    "            print(f\"OC SVM Sucessfully fit, training time: {time.time()-start_time}\")\n",
    "\n",
    "    def predict_if_outlier(self, predict_data_loader):\n",
    "        image_to_feature_transform = self.neural_net[:-2].eval()\n",
    "\n",
    "        oc_svm_data_transforms = transforms.Compose(\n",
    "            [\n",
    "                lambda x: x.view(-1, 28 ** 2),\n",
    "                lambda x: image_to_feature_transform(x),\n",
    "                lambda x: x.detach().numpy(),\n",
    "                lambda x: x.flatten(),\n",
    "            ]\n",
    "        )\n",
    "        predictions = list()\n",
    "        for image in next(iter(predict_data_loader))[0]:\n",
    "            predictions.extend([oc_svm_data_transforms(im) for im in image])\n",
    "        results = self.oc_svm.predict(predictions)\n",
    "        return results\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.neural_net.__repr__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic neural net for Fashion MNIST pictures\n",
    "Let's build a quick neural net in pytorch to classify clothes from Fashion MNIST. I'm assuming if you're this far deep into machine learning, you likely have encountered this before. If you are unsure about the basics of Neural Networks as classifiers, you should check out an in depth tutorial for the nitty-gritty details. We're doing this in a standard but terse approach.\n",
    "\n",
    "### The general idea:\n",
    "\n",
    "In training a neural network we are transforming images into feature maps and feeding that into the final fully connected layer that corresponds to our classes. Once we have a model with the performance we like, we separate the final layer from the rest of the neural net. We then use this feature extractor on our training set to generate our training data for the one-class SVM.\n",
    "\n",
    "Why do we care? Because then we can do this on incoming data and check if the incoming image data is anomalous. Depending on your use case this can mean auto-flagging useful and novel future training data or could mean flagging potentially fraudulent or dangerous input.\n",
    "\n",
    "This will be demonstrated with a fashion MNIST classifier with the hope to have the OC-SVM flag input images that are not clothes (noise, patterns, or non-clothing objects like cats).\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. Load up Fashion MNIST dataset and setup data pipeline\n",
    "2. Construct Fully Connected Neural Net in pytorch and train\n",
    "3. Freeze model and separate the last fully connected layer from model\n",
    "    * Ideally we can pass the vector straight to the last layer\n",
    "4. Use the feature extractor to generate data for our OC-SVM model\n",
    "\n",
    "Once that is complete we'll have the first component of our lovely model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Creating the data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading up our transformers so images get preprocessed\n",
    "# TODO Add robust preprocessing so it'll work out of the box for more realistic problems\n",
    "image_preprocessing_pipeline = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),  # Convert image to tensor\n",
    "        transforms.Normalize((0.5,), (0.5,)),  # Normalize RGB values from 0-255 to 0-1\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Building dataset\n",
    "training_data = datasets.FashionMNIST(\n",
    "    \".\", train=True, transform=image_preprocessing_pipeline, download=False\n",
    ")\n",
    "\n",
    "validation_data = datasets.FashionMNIST(\n",
    "    \".\", train=False, transform=image_preprocessing_pipeline, download=False\n",
    ")\n",
    "\n",
    "# Setting up data loaders.\n",
    "training_data_loader = torch.utils.data.DataLoader(\n",
    "    training_data, batch_size=64, shuffle=True\n",
    ")\n",
    "\n",
    "validation_data_loader = torch.utils.data.DataLoader(\n",
    "    validation_data, batch_size=64, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build the Neural Network classifier\n",
    "\n",
    "We build a simple fully connected neural network. Our input layer takes in our 28x28 image and flattens it out. We pass it through an activation function (ReLU) and through a hidden layer before outputting to a final fully connected layer and a softmax activation layer so our image turns into a feature vector and finally class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_basic_neural_net_structure(\n",
    "    input_size=28 * 28, hidden_sizes=[128, 64], number_of_classes=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates basic neural network with an input layer, feature extraction layer, and output layer.\n",
    "    Basic structure:\n",
    "        Input: linear layer of image resolution (color * width * height) and ReLU activation\n",
    "        Hidden: linear layer of hidden sizes and RelU activation\n",
    "        Output: liear layer and LogSoftmax activation to final size of number_of_classes\n",
    "    parameters:\n",
    "        input_size: number of neurons in input layer\n",
    "        hidden_sizes: in_feature and out_feature sizes as ints. \n",
    "    returns: Sequential neural net for training and inference.\n",
    "    \"\"\"\n",
    "    if not isinstance(input_size, int):\n",
    "        raise TypeError(\n",
    "            f\"Input size must be an integer, received type {type(input_size)}\"\n",
    "        )\n",
    "    if input_size <= 0:\n",
    "        raise ValueError(\n",
    "            f\"Input must be greater than 0 and an integer, received {input_size}\"\n",
    "        )\n",
    "\n",
    "    input_layer_dimensions = (\n",
    "        (input_size, hidden_sizes[0])\n",
    "        if len(hidden_sizes) != 0\n",
    "        else (input_size, number_of_classes)\n",
    "    )\n",
    "    input_layers = [nn.Linear(*input_layer_dimensions), nn.ReLU()]\n",
    "\n",
    "    if len(hidden_sizes) == 0:\n",
    "        hidden_layers = list()\n",
    "    else:\n",
    "        hidden_layers = [\n",
    "            layer\n",
    "            for dims in zip(hidden_sizes[:-1], hidden_sizes[1:])\n",
    "            for layer in (nn.Linear(*dims), nn.ReLU())\n",
    "        ]\n",
    "\n",
    "    final_output_layer_dimensions = (\n",
    "        (hidden_sizes[-1], number_of_classes)\n",
    "        if len(hidden_sizes) != 0\n",
    "        else (input_size, number_of_classes)\n",
    "    )\n",
    "\n",
    "    final_output_layer = [nn.Linear(*final_output_layer_dimensions), nn.LogSoftmax()]\n",
    "\n",
    "    model_structure_list = list()\n",
    "    for structure in [input_layers, hidden_layers, final_output_layer]:\n",
    "        model_structure_list.extend(structure)\n",
    "\n",
    "    model = nn.Sequential(*model_structure_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some basic tests on our helper function to generate a fully connected neural network for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_size = 28 * 28\n",
    "test_hidden_sizes = [128, 64]\n",
    "test_number_of_classes = 10\n",
    "\n",
    "base_mnist_model_structure = nn.Sequential(\n",
    "    nn.Linear(28 * 28, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10),\n",
    "    nn.LogSoftmax(),\n",
    ")\n",
    "\n",
    "### Testing of improper input_size parameters\n",
    "for improper_input_size in [0, -10, -1000, None, 293.4, \"foobar\"]:\n",
    "\n",
    "    try:\n",
    "        create_basic_neural_net_structure(input_size=improper_input_size)\n",
    "\n",
    "    except ValueError as good_error:\n",
    "        assert str(\n",
    "            ValueError(\n",
    "                f\"Input must be greater than 0 and an integer, received {improper_input_size}\"\n",
    "            )\n",
    "        ) == str(good_error)\n",
    "\n",
    "    except TypeError as good_error:\n",
    "        assert str(good_error) == str(\n",
    "            TypeError(\n",
    "                f\"Input size must be an integer, received type {type(improper_input_size)}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "# This is for testing that valid input sizes (cooresponding to 28x28, 50x50, and 300x300 grayscale image resolutions) create networks as expected\n",
    "for test_input_size in [28 ** 2, 50 ** 2, 300 ** 2]:\n",
    "    test_mnist_model = create_basic_neural_net_structure(\n",
    "        test_input_size, test_hidden_sizes, test_number_of_classes\n",
    "    )\n",
    "\n",
    "    base_mnist_model_structure = nn.Sequential(\n",
    "        nn.Linear(test_input_size, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 10),\n",
    "        nn.LogSoftmax(),\n",
    "    )\n",
    "\n",
    "    # This asserts that the models contain the same number of layers\n",
    "    assert len(test_mnist_model) == len(base_mnist_model_structure)\n",
    "\n",
    "    for idx, layers in enumerate(zip(base_mnist_model_structure, test_mnist_model)):\n",
    "        if idx % 2 != 0:\n",
    "            # We skip every 2nd layer as they're the ReLU activation layers.\n",
    "            continue\n",
    "        else:\n",
    "            # Confirming our layers both match in their dimensions\n",
    "            their_layer, our_layer = layers\n",
    "            assert their_layer.in_features == our_layer.in_features\n",
    "            assert their_layer.out_features == our_layer.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick detour for looking at our data\n",
    "\n",
    "Let's take a quick look at the shape, label, and how we transform the data before feeding it to our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note the shape of a single image: \n",
      " torch.Size([1, 28, 28])\n",
      "Post numpy and squeeze gives us a 28x28 matrix representation of our image with shape: \n",
      "    (28, 28)\n",
      "this example image is a Sneaker\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick convenient dictionary for mapping IDX to label\n",
    "\n",
    "label_map = {\n",
    "    0: \"T-shirt/Top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "\n",
    "images, labels = next(iter(training_data_loader))\n",
    "print(f\"Note the shape of a single image: \\n {images[0].shape}\")\n",
    "example_image = images[0].numpy().squeeze()\n",
    "print(\n",
    "    f\"Post numpy and squeeze gives us a 28x28 matrix representation of our image with shape: \\n    {example_image.shape}\"\n",
    ")\n",
    "plt.imshow(example_image, cmap=\"gray_r\")\n",
    "print(f\"this example image is a {label_map.get(labels[0].item())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay enough belly-achin, let's test our work!\n",
    "\n",
    "We create the neural network, select our criterion and optimizer, then load up the model and run training and evaluation.\n",
    "\n",
    "* model: this is a FC-NN but any pytorch Squential neural network can work, as long as you can strip off the output layer\n",
    "* criterion: the criterion the neural network is evaluated on. Here we use negative log-likelihood because we're doing classification.\n",
    "* optimizer: the optimizer for training your neural net. We use stochastic gradient descent here. I've frequently had good experience using optim.Adam in other projects. When in doubt, cross-validate! Here we keep it basic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erin/anaconda3/envs/cnn_oc_svm/lib/python3.8/site-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training loss: 0.8460309876879649\n",
      "Epoch 2 - Training loss: 0.4634871239156357\n",
      "Epoch 3 - Training loss: 0.4066933798732788\n",
      "Training time (s): 38.09494972229004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4066933798732788"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_basic_neural_net_structure(hidden_sizes=[256, 128, 128])\n",
    "criterion = (\n",
    "    nn.NLLLoss()\n",
    ")  # Negative log-likelihood loss which is used because we're doing classification\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
    "\n",
    "our_latest_and_greatest = cnn_oc_svm(model, criterion, optimizer)\n",
    "\n",
    "our_latest_and_greatest.training(\n",
    "    epochs=3, learning_rate=0.003, training_data_loader=training_data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Training took ~30s on an i7-8565U with 24gb ram and no GPU.\n",
    "\n",
    "The evaluation results show we get ~84.4% accuracy. For reference average human performance with no fashion experience is about 83.5%, so we're already doing better than people!\n",
    "\n",
    "This also has the similar performance as:\n",
    "* Random forest classifiers (n_estimators of 50 or 100, max_depth = 10)\n",
    "* Logistic Regression (l1 penalty and multi_class is 'ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images tested: 10000 \n",
      " Classification Accuracy: 0.8438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8438"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_latest_and_greatest.evaluation(validation_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the OC-SVM on our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting One Class SVM on 60032 data points\n",
      "OC SVM Sucessfully fit, training time: 714.6767659187317\n"
     ]
    }
   ],
   "source": [
    "our_latest_and_greatest.train_oc_svm(training_data_loader)\n",
    "# training_data_loader.dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_svm_evaluation_data = datasets.MNIST(\n",
    "    \".\", train=False, transform=image_preprocessing_pipeline, download=True\n",
    ")\n",
    "oc_svm_evaluation_data_loader = torch.utils.data.DataLoader(\n",
    "    oc_svm_evaluation_data, batch_size=64, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = our_latest_and_greatest.predict_if_outlier(oc_svm_evaluation_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right, wrong = np.unique(results, return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.25"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right / (wrong + right) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

---

title: cnn_oc_svm

keywords: fastai
sidebar: home_sidebar

summary: "Contains the base class for the CNN OC-SVM model. Override the SVM or CNN as desired but used directly is optimized for the MNIST example case."
description: "Contains the base class for the CNN OC-SVM model. Override the SVM or CNN as desired but used directly is optimized for the MNIST example case."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 00_cnn_oc_svm.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="cnn_oc_svm" class="doc_header"><code>class</code> <code>cnn_oc_svm</code><a href="https://github.com/ErinMyLungs/cnn_oc_svm/tree/master/cnn_oc_svm/cnn_oc_svm.py#L6" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>cnn_oc_svm</code>()</p>
</blockquote>
<p>The base-class with simple CNN and OC-SVM.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Basic-neural-net-for-mnist-digits">Basic neural net for mnist digits<a class="anchor-link" href="#Basic-neural-net-for-mnist-digits"> </a></h3><p>Let's build a quick neural net in pytorch to classify MNIST digits. I'm assuming if you're this far deep into machine learning, you likely have encountered this before. If you are unsure about the basics of Neural Networks as classifiers, you should check out an in depth tutorial for the nitty-gritty details. We're doing this in a standard but terse approach.</p>
<h3 id="The-general-idea:">The general idea:<a class="anchor-link" href="#The-general-idea:"> </a></h3><p>In training a neural network we are transforming images into feature maps and feeding that into the final fully connected layer that corresponds to our classes. Once we have a model with the performance we like, we separate the final layer from the rest of the neural net. We then use this feature extractor on our training set to generate our training data for the one-class SVM.</p>
<p>Why do we care? Because then we can do this on incoming data and check if the incoming image data is anomalous. Depending on your use case this can mean auto-flagging useful and novel future training data or could mean flagging potentially fraudulent or dangerous input.</p>
<p>This will be demonstrated with an MNIST classifier with the hope to have the OC-SVM flag input images that are not numbers but random images, patterns, and possibly even letters.</p>
<h3 id="Steps:">Steps:<a class="anchor-link" href="#Steps:"> </a></h3><ol>
<li>Load up MNIST dataset and setup data pipeline</li>
<li>Construct CNN in pytorch and train</li>
<li>Freeze model and separate the last fully connected layer from model<ul>
<li>Ideally we can pass the vector straight to the last layer</li>
</ul>
</li>
<li>Use the feature extractor to generate data for our OC-SVM model</li>
</ol>
<p>Once that is complete we'll have the first component of our lovely model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-1:-Creating-the-data-pipeline">Step 1: Creating the data pipeline<a class="anchor-link" href="#Step-1:-Creating-the-data-pipeline"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Loading up our transformers so images get preprocessed</span>
<span class="c1"># TODO Add robust preprocessing so it&#39;ll work out of the box for more realistic problems</span>
<span class="n">image_preprocessing_pipeline</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                               <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="c1">#Convert image to tensor</span>
                               <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,)),</span> <span class="c1"># Normalize RGB values from 0-255 to 0-1</span>
                               <span class="p">])</span>

<span class="c1"># Building dataset</span>
<span class="n">training_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">image_preprocessing_pipeline</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">validation_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">image_preprocessing_pipeline</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Setting up data loaders.</span>
<span class="n">training_data_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">validation_data_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">validation_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-2:-Build-the-CNN">Step 2: Build the CNN<a class="anchor-link" href="#Step-2:-Build-the-CNN"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">input_size</span> <span class="o">=</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span> <span class="c1">#Image resolution is 28x28</span>
<span class="n">hidden_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">output_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">model</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span> <span class="c1">#Negative log-likelihood loss cuz classification</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Sequential(
  (0): Linear(in_features=784, out_features=128, bias=True)
  (1): ReLU()
  (2): Linear(in_features=128, out_features=64, bias=True)
  (3): ReLU()
  (4): Linear(in_features=64, out_features=10, bias=True)
  (5): LogSoftmax()
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">training_data_loader</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Note the shape of a single image: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">example_image</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Post numpy and squeeze gives us a 28x28 matrix representation of our image: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">example_image</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">example_image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray_r&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Note the shape of a single image: 
 torch.Size([1, 28, 28])
Post numpy and squeeze gives us a 28x28 matrix representation of our image: 
 (28, 28)
&lt;built-in method values of Tensor object at 0x7f359ecd5d80&gt;
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">example_image</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(28, 28)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

